{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pyspark Dataframe\n",
    "- Reading the Dataset\n",
    "- Cheking the datatype  of the column(schema)\n",
    "- Selecting columns and indexing\n",
    "- check described option semilar to pandas \n",
    "- Adding columns\n",
    "- Droping Colimns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import spark session \n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Dataframe').getOrCreate()  # store in variable  # actually start a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-55S106J:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19c236a29b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df_pyspark=spark.read.option('header','true').csv('mtcars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv('mtcars.csv',inferSchema=True) # inferSchema = true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
      "+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|  21|  6|  160|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
      "|  21|  6|  160|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
      "|22.8|  4|  108| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
      "|21.4|  6|  258|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
      "|18.7|  8|  360|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
      "|18.1|  6|  225|105|2.76| 3.46|20.22|  1|  0|   3|   1|\n",
      "|14.3|  8|  360|245|3.21| 3.57|15.84|  0|  0|   3|   4|\n",
      "|24.4|  4|146.7| 62|3.69| 3.19|   20|  1|  0|   4|   2|\n",
      "|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|\n",
      "|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|\n",
      "+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header','true').csv('mtcars.csv').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- cyl: integer (nullable = true)\n",
      " |-- disp: double (nullable = true)\n",
      " |-- hp: integer (nullable = true)\n",
      " |-- drat: double (nullable = true)\n",
      " |-- wt: double (nullable = true)\n",
      " |-- qsec: double (nullable = true)\n",
      " |-- vs: integer (nullable = true)\n",
      " |-- am: integer (nullable = true)\n",
      " |-- gear: integer (nullable = true)\n",
      " |-- carb: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the schema (datatype)\n",
    "df_pyspark.printSchema()   # bydefault it take datatype as 'string' resone is, we need to give inferschema=True while reading the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
      "+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
      "|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
      "|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
      "|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
      "|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
      "|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|\n",
      "|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|\n",
      "|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|\n",
      "|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|\n",
      "|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|\n",
      "|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|\n",
      "|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|\n",
      "|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|\n",
      "|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|\n",
      "|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4|\n",
      "|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4|\n",
      "|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|\n",
      "|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|\n",
      "|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|\n",
      "|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|\n",
      "+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('mtcars.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- cyl: integer (nullable = true)\n",
      " |-- disp: double (nullable = true)\n",
      " |-- hp: integer (nullable = true)\n",
      " |-- drat: double (nullable = true)\n",
      " |-- wt: double (nullable = true)\n",
      " |-- qsec: double (nullable = true)\n",
      " |-- vs: integer (nullable = true)\n",
      " |-- am: integer (nullable = true)\n",
      " |-- gear: integer (nullable = true)\n",
      " |-- carb: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the schema (datatype)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mpg', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how we can get all the columns\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cyl: int]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to pickup the columns\n",
    "df_pyspark.select('cyl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|cyl|\n",
      "+---+\n",
      "|  6|\n",
      "|  6|\n",
      "|  4|\n",
      "|  6|\n",
      "|  8|\n",
      "|  6|\n",
      "|  8|\n",
      "|  4|\n",
      "|  4|\n",
      "|  6|\n",
      "|  6|\n",
      "|  8|\n",
      "|  8|\n",
      "|  8|\n",
      "|  8|\n",
      "|  8|\n",
      "|  8|\n",
      "|  4|\n",
      "|  4|\n",
      "|  4|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how to pickup the columns\n",
    "df_pyspark.select('cyl').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select('cyl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cyl: int, disp: double, hp: int]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pickup multiple columns\n",
    "df_pyspark.select(['cyl','disp','hp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "|cyl| disp| hp|\n",
      "+---+-----+---+\n",
      "|  6|160.0|110|\n",
      "|  6|160.0|110|\n",
      "|  4|108.0| 93|\n",
      "|  6|258.0|110|\n",
      "|  8|360.0|175|\n",
      "|  6|225.0|105|\n",
      "|  8|360.0|245|\n",
      "|  4|146.7| 62|\n",
      "|  4|140.8| 95|\n",
      "|  6|167.6|123|\n",
      "|  6|167.6|123|\n",
      "|  8|275.8|180|\n",
      "|  8|275.8|180|\n",
      "|  8|275.8|180|\n",
      "|  8|472.0|205|\n",
      "|  8|460.0|215|\n",
      "|  8|440.0|230|\n",
      "|  4| 78.7| 66|\n",
      "|  4| 75.7| 52|\n",
      "|  4| 71.1| 65|\n",
      "+---+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['cyl','disp','hp']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### in pyspark slicing not possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mpg', 'double'),\n",
       " ('cyl', 'int'),\n",
       " ('disp', 'double'),\n",
       " ('hp', 'int'),\n",
       " ('drat', 'double'),\n",
       " ('wt', 'double'),\n",
       " ('qsec', 'double'),\n",
       " ('vs', 'int'),\n",
       " ('am', 'int'),\n",
       " ('gear', 'int'),\n",
       " ('carb', 'int')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, mpg: string, cyl: string, disp: string, hp: string, drat: string, wt: string, qsec: string, vs: string, am: string, gear: string, carb: string]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|summary|               mpg|               cyl|              disp|               hp|              drat|                wt|              qsec|                vs|                 am|              gear|              carb|\n",
      "+-------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|  count|                32|                32|                32|               32|                32|                32|                32|                32|                 32|                32|                32|\n",
      "|   mean|20.090624999999996|            6.1875|230.72187500000004|         146.6875|3.5965625000000006|3.2172499999999995|17.848750000000003|            0.4375|            0.40625|            3.6875|            2.8125|\n",
      "| stddev| 6.026948052089103|1.7859216469465444|123.93869383138195|68.56286848932059|0.5346787360709716|0.9784574429896968|1.7869432360968436|0.5040161287741853|0.49899091723584604|0.7378040652569471|1.6151999776318522|\n",
      "|    min|              10.4|                 4|              71.1|               52|              2.76|             1.513|              14.5|                 0|                  0|                 3|                 1|\n",
      "|    max|              33.9|                 8|             472.0|              335|              4.93|             5.424|              22.9|                 1|                  1|                 5|                 8|\n",
      "+-------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[mpg: double, cyl: int, disp: double, hp: int, drat: double, wt: double, qsec: double, vs: int, am: int, gear: int, carb: int, hp after 2 years: int]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding Columns in pyspark dataframe\n",
    "df_pyspark.withColumn('hp after 2 years',df_pyspark['hp']+2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+---+----+-----+-----+---+---+----+----+----------------+\n",
      "| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|hp after 2 years|\n",
      "+----+---+-----+---+----+-----+-----+---+---+----+----+----------------+\n",
      "|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|             112|\n",
      "|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|             112|\n",
      "|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|              95|\n",
      "|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|             112|\n",
      "|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|             177|\n",
      "|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|             107|\n",
      "|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|             247|\n",
      "|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|              64|\n",
      "|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|              97|\n",
      "|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|             125|\n",
      "|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|             125|\n",
      "|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|             182|\n",
      "|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|             182|\n",
      "|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|             182|\n",
      "|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4|             207|\n",
      "|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4|             217|\n",
      "|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|             232|\n",
      "|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|              68|\n",
      "|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|              54|\n",
      "|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|              67|\n",
      "+----+---+-----+---+----+-----+-----+---+---+----+----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumn('hp after 2 years',df_pyspark['hp']+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[mpg: double, cyl: int, disp: double, hp: int, drat: double, wt: double, qsec: double, vs: int, am: int, gear: int, carb: int]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dro the Columns\n",
    "df_pyspark.drop('hp after 2 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
      "+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
      "|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
      "|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
      "|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
      "|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
      "|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|\n",
      "|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|\n",
      "|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|\n",
      "|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|\n",
      "|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|\n",
      "|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|\n",
      "|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|\n",
      "|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|\n",
      "|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|\n",
      "|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4|\n",
      "|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4|\n",
      "|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|\n",
      "|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|\n",
      "|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|\n",
      "|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|\n",
      "+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.drop('hp after 2 years').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[mpg: double, cyl: int, disp: double, hp: int, drat: double, wt: double, qsec: double, vs: int, am: int, gear: int, new carb: int]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REname the columns\n",
    "df_pyspark.withColumnRenamed('carb','new carb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+---+----+-----+-----+---+---+----+--------+\n",
      "| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|new carb|\n",
      "+----+---+-----+---+----+-----+-----+---+---+----+--------+\n",
      "|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|       4|\n",
      "|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|       4|\n",
      "|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|       1|\n",
      "|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|       1|\n",
      "|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|       2|\n",
      "|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|       1|\n",
      "|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|       4|\n",
      "|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|       2|\n",
      "|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|       2|\n",
      "|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|       4|\n",
      "|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|       4|\n",
      "|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|       3|\n",
      "|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|       3|\n",
      "|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|       3|\n",
      "|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|       4|\n",
      "|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|       4|\n",
      "|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|       4|\n",
      "|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|       1|\n",
      "|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|       2|\n",
      "|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|       1|\n",
      "+----+---+-----+---+----+-----+-----+---+---+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed('carb','new carb').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
